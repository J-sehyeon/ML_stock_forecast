{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c4a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea801319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model('gpt-5-nano')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e47d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='좋아요. LangChain은 복잡한 체인형 작업을 쉽게 구성하고, LLM을 중심으로 프롬프트 관리, 도구 사용, 대화 기억 등을 한 곳에서 다루게 해주는 라이브러리입니다. 아래에 초보자용 가이드와 핵심 개념, 빠른 시작 예제, 실전 패턴까지 간단히 정리해둘게요.\\n\\n1) LangChain이란\\n- 목적: LLM을 이용한 질의응답, 요약, 정보 추출 등 다양한 작업을 \"체인(chain)\"으로 연결하고, 필요하면 도구(Tool)나 메모리(Memory)까지 연결해 강력한 파이프라인을 만들 수 있게 해줌.\\n- 지원 언어: Python용과 JavaScript/TypeScript용이 있습니다. 여기서는 Python 예제를 중심으로 설명하되, JS/TS도 필요하면 안내해 드립니다.\\n\\n2) 설치 및 기본 설정\\n- 기본 설치:\\n  - Python: pip install langchain openai\\n  - API 키 설정(예: OpenAI): OPENAI_API_KEY 환경 변수에 키를 설정하거나 코드에서 설정합니다.\\n- 간단한 예제 준비:\\n  - import, LLM 초기화, 프롬프트 템플릿 생성, 체인 구성, 실행\\n  - 예시 코드(가장 기본적인 LLMChain):\\n    - import: from langchain.llms import OpenAI\\n    - import: from langchain.prompts import PromptTemplate\\n    - import: from langchain.chains import LLMChain\\n    - llm = OpenAI(temperature=0)\\n    - template = PromptTemplate(input_variables=[\"name\"], template=\"Hello {name}!\")\\n    - chain = LLMChain(llm=llm, prompt=template)\\n    - result = chain.run({\"name\": \"Alice\"})\\n\\n3) 핵심 구성 요소(개념 정리)\\n- LLM(대형언어모델): 실제 답변을 생성하는 모델. OpenAI의 GPT 계열, Cohere, HuggingFace 등 다양한 백엔드를 사용할 수 있음.\\n- PromptTemplate: 프롬프트를 미리 정의하고 입력 변수를 바인딩하는 도구. 재사용 가능한 프롬프트 구성에 유용.\\n- Chains: LLMChain, SequentialChain 등으로 구성된 작업 흐름. 여러 프롬프트/LLM 호출을 순차적으로 연결.\\n- Tools(도구): 외부 API 호출, 계산, 코드 실행 등 LLM이 필요한 작업을 수행하게 하는 보조 기능. 예: Python REPL, 검색 도구, 데이터베이스 질의 등.\\n- Agents(에이전트): LLM이 도구를 사용하도록 지시하고, 상황에 맞춰 문제를 해결하도록 돕는 고급 흐름. 제시된 도메인에서 필요한 도구를 선택해 스스로 문제를 해결.\\n- Memory(메모리): 대화 맥락이나 상태를 기억해 다음 단계에서 활용. 예: 이전 대화 요약 저장, 사용자의 선호 기억 등.\\n- Vector Store(벡터 저장소): 롬에 저장된 문서나 지식 조각을 임베딩으로 인덱싱해 검색에 활용. Retrieval-Augmented Generation(RAG) 패턴에 많이 사용.\\n\\n4) 빠른 시작 예제 2가지\\nA. 가장 기본적인 LLMChain 사용\\n- 목표: 간단한 인사 메시지 생성\\n  - 코드 흐름:\\n    - llm = OpenAI(temperature=0)\\n    - prompt = PromptTemplate(input_variables=[\"name\"], template=\"Hi {name}, nice to meet you.\")\\n    - chain = LLMChain(llm=llm, prompt=prompt)\\n    - print(chain.run({\"name\": \"홍길동\"}))\\n\\nB. 간단한 에이전트 예제(도구를 사용할 수 있도록 하는 기본 아이디어)\\n- 목표: 간단한 작업에 대해 도구를 활용하는 흐름 구축\\n  - 흐름 요약:\\n    - Python REPL 도구나 검색 도구 같은 간단한 도구를 만들어 연결\\n    - 에이전트가 질문에 맞춰 도구를 호출하고 결과를 바탕으로 응답\\n  - 주의: 실제 사용 시 import 위치나 도구 생성 방식은 LangChain 버전에 따라 다를 수 있습니다. 공식 문서를 버전에 맞춰 확인하세요.\\n  - 시작점으로는 “Python REPL 도구”를 사용해 간단한 산술 계산이나 코드 실행을 시도하는 예제가 많이 제공됩니다.\\n\\n5) 실전에서 자주 쓰는 패턴\\n- Q&A with memory: 대화 맥락을 기억해 이전 대화 내용을 참고하며 질문에 답하기.\\n- 요약 + 질의응답: 긴 문서를 요약한 뒤 핵심 질문에 답하기.\\n- 데이터 추출: 텍스트에서 특정 필드(날짜, 수치, 이름 등) 추출 및 정리.\\n- 지식 기반 검색 + 보강: 벡터 스토어에 문서를 저장하고, 질의 시 유사 문서를 검색해 LLM이 보강된 답변을 생성하도록 하기.\\n- 작업 자동화 에이전트: 여러 도구(파일 시스템, API, 데이터베이스 등)를 조합해 복잡한 작업 흐름 자동화.\\n\\n6) 설정 및 운영 팁\\n- API 키 관리: 개발 중에는 테스트 키를, 배포 시에는 비밀 관리 시스템을 사용해 안전하게 관리.\\n- 버전 관리: LangChain은 빠르게 업데이트되므로 버전에 따라 API가 다소 바뀔 수 있습니다. 사용하는 버전에 맞춘 공식 문서를 항상 확인.\\n- 예외 처리: 네트워크 이슈나 API 한도 초과 등 예외 상황에 대비한 retry 로직이나 타임아웃 설정 활용.\\n- 로깅/디버깅: verbose 모드나 로그를 활성화해 체인 실행 흐름을 추적하고 문제를 빠르게 파악.\\n\\n7) 어떤 환경에서 시작할지 선택하기\\n- Python으로 시작: 가장 많이 사용되고 예제가 풍부합니다. 데이터 처리 파이프라인이나 백엔드 서비스에 바로 통합하기 쉽습니다.\\n- JavaScript/TypeScript로 시작: 프론트엔드나 Node.js 서버 사이드에서 바로 LLM 기반 기능을 구현하기 좋습니다.\\n- 특정 도구 활용 여부: 예를 들어 웹 검색이 필요하면 SerpAPI 도구, 코드 실행이 필요하면 PythonREPL 도구 등 필요 도구를 먼저 파악하고 시작하면 좋습니다.\\n\\n8) 도움이 더 필요하면\\n- 사용 목표를 알려주시면 더 구체적인 예제와 코드 스니펫을 맞춤으로 드릴게요.\\n  - 예: Python으로 간단한 Q&A 체인 만들기, 메모리 있는 대화형 에이전트 구성, 벡터 스토어를 이용한 문서 검색 시스템 구축, Node.js에서 LangChain 사용하기 등\\n- 또한 사용하는 버전(예: LangChain Python v0.x, v0. long-term)과 백엔드(Linode, OpenAI, Cohere 등)를 알려주시면 정확한 import 경로와 코드 예제를 제공합니다.\\n\\n원하시면 바로 따라 할 수 있는 간단한 Python 빠른 시작 코드와, 자주 쓰는 패턴별 예제(메모리 있는 대화, 벡터 스토어 연결, 간단한 에이전트)를 하나의 연속 예제로 만들어 드리겠습니다. 어떤 분야나 사용 사례부터 시작하고 싶으신가요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 3347, 'prompt_tokens': 10, 'total_tokens': 3357, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1728, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-DA7EjlhzyfcBveGlmZQrT9aaLbZw3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c69ea-0191-7810-80f7-578e9c1df04b-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 10, 'output_tokens': 3347, 'total_tokens': 3357, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1728}}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke('langchain 사용법')\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "903c9084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'좋아요. LangChain은 복잡한 체인형 작업을 쉽게 구성하고, LLM을 중심으로 프롬프트 관리, 도구 사용, 대화 기억 등을 한 곳에서 다루게 해주는 라이브러리입니다. 아래에 초보자용 가이드와 핵심 개념, 빠른 시작 예제, 실전 패턴까지 간단히 정리해둘게요.\\n\\n1) LangChain이란\\n- 목적: LLM을 이용한 질의응답, 요약, 정보 추출 등 다양한 작업을 \"체인(chain)\"으로 연결하고, 필요하면 도구(Tool)나 메모리(Memory)까지 연결해 강력한 파이프라인을 만들 수 있게 해줌.\\n- 지원 언어: Python용과 JavaScript/TypeScript용이 있습니다. 여기서는 Python 예제를 중심으로 설명하되, JS/TS도 필요하면 안내해 드립니다.\\n\\n2) 설치 및 기본 설정\\n- 기본 설치:\\n  - Python: pip install langchain openai\\n  - API 키 설정(예: OpenAI): OPENAI_API_KEY 환경 변수에 키를 설정하거나 코드에서 설정합니다.\\n- 간단한 예제 준비:\\n  - import, LLM 초기화, 프롬프트 템플릿 생성, 체인 구성, 실행\\n  - 예시 코드(가장 기본적인 LLMChain):\\n    - import: from langchain.llms import OpenAI\\n    - import: from langchain.prompts import PromptTemplate\\n    - import: from langchain.chains import LLMChain\\n    - llm = OpenAI(temperature=0)\\n    - template = PromptTemplate(input_variables=[\"name\"], template=\"Hello {name}!\")\\n    - chain = LLMChain(llm=llm, prompt=template)\\n    - result = chain.run({\"name\": \"Alice\"})\\n\\n3) 핵심 구성 요소(개념 정리)\\n- LLM(대형언어모델): 실제 답변을 생성하는 모델. OpenAI의 GPT 계열, Cohere, HuggingFace 등 다양한 백엔드를 사용할 수 있음.\\n- PromptTemplate: 프롬프트를 미리 정의하고 입력 변수를 바인딩하는 도구. 재사용 가능한 프롬프트 구성에 유용.\\n- Chains: LLMChain, SequentialChain 등으로 구성된 작업 흐름. 여러 프롬프트/LLM 호출을 순차적으로 연결.\\n- Tools(도구): 외부 API 호출, 계산, 코드 실행 등 LLM이 필요한 작업을 수행하게 하는 보조 기능. 예: Python REPL, 검색 도구, 데이터베이스 질의 등.\\n- Agents(에이전트): LLM이 도구를 사용하도록 지시하고, 상황에 맞춰 문제를 해결하도록 돕는 고급 흐름. 제시된 도메인에서 필요한 도구를 선택해 스스로 문제를 해결.\\n- Memory(메모리): 대화 맥락이나 상태를 기억해 다음 단계에서 활용. 예: 이전 대화 요약 저장, 사용자의 선호 기억 등.\\n- Vector Store(벡터 저장소): 롬에 저장된 문서나 지식 조각을 임베딩으로 인덱싱해 검색에 활용. Retrieval-Augmented Generation(RAG) 패턴에 많이 사용.\\n\\n4) 빠른 시작 예제 2가지\\nA. 가장 기본적인 LLMChain 사용\\n- 목표: 간단한 인사 메시지 생성\\n  - 코드 흐름:\\n    - llm = OpenAI(temperature=0)\\n    - prompt = PromptTemplate(input_variables=[\"name\"], template=\"Hi {name}, nice to meet you.\")\\n    - chain = LLMChain(llm=llm, prompt=prompt)\\n    - print(chain.run({\"name\": \"홍길동\"}))\\n\\nB. 간단한 에이전트 예제(도구를 사용할 수 있도록 하는 기본 아이디어)\\n- 목표: 간단한 작업에 대해 도구를 활용하는 흐름 구축\\n  - 흐름 요약:\\n    - Python REPL 도구나 검색 도구 같은 간단한 도구를 만들어 연결\\n    - 에이전트가 질문에 맞춰 도구를 호출하고 결과를 바탕으로 응답\\n  - 주의: 실제 사용 시 import 위치나 도구 생성 방식은 LangChain 버전에 따라 다를 수 있습니다. 공식 문서를 버전에 맞춰 확인하세요.\\n  - 시작점으로는 “Python REPL 도구”를 사용해 간단한 산술 계산이나 코드 실행을 시도하는 예제가 많이 제공됩니다.\\n\\n5) 실전에서 자주 쓰는 패턴\\n- Q&A with memory: 대화 맥락을 기억해 이전 대화 내용을 참고하며 질문에 답하기.\\n- 요약 + 질의응답: 긴 문서를 요약한 뒤 핵심 질문에 답하기.\\n- 데이터 추출: 텍스트에서 특정 필드(날짜, 수치, 이름 등) 추출 및 정리.\\n- 지식 기반 검색 + 보강: 벡터 스토어에 문서를 저장하고, 질의 시 유사 문서를 검색해 LLM이 보강된 답변을 생성하도록 하기.\\n- 작업 자동화 에이전트: 여러 도구(파일 시스템, API, 데이터베이스 등)를 조합해 복잡한 작업 흐름 자동화.\\n\\n6) 설정 및 운영 팁\\n- API 키 관리: 개발 중에는 테스트 키를, 배포 시에는 비밀 관리 시스템을 사용해 안전하게 관리.\\n- 버전 관리: LangChain은 빠르게 업데이트되므로 버전에 따라 API가 다소 바뀔 수 있습니다. 사용하는 버전에 맞춘 공식 문서를 항상 확인.\\n- 예외 처리: 네트워크 이슈나 API 한도 초과 등 예외 상황에 대비한 retry 로직이나 타임아웃 설정 활용.\\n- 로깅/디버깅: verbose 모드나 로그를 활성화해 체인 실행 흐름을 추적하고 문제를 빠르게 파악.\\n\\n7) 어떤 환경에서 시작할지 선택하기\\n- Python으로 시작: 가장 많이 사용되고 예제가 풍부합니다. 데이터 처리 파이프라인이나 백엔드 서비스에 바로 통합하기 쉽습니다.\\n- JavaScript/TypeScript로 시작: 프론트엔드나 Node.js 서버 사이드에서 바로 LLM 기반 기능을 구현하기 좋습니다.\\n- 특정 도구 활용 여부: 예를 들어 웹 검색이 필요하면 SerpAPI 도구, 코드 실행이 필요하면 PythonREPL 도구 등 필요 도구를 먼저 파악하고 시작하면 좋습니다.\\n\\n8) 도움이 더 필요하면\\n- 사용 목표를 알려주시면 더 구체적인 예제와 코드 스니펫을 맞춤으로 드릴게요.\\n  - 예: Python으로 간단한 Q&A 체인 만들기, 메모리 있는 대화형 에이전트 구성, 벡터 스토어를 이용한 문서 검색 시스템 구축, Node.js에서 LangChain 사용하기 등\\n- 또한 사용하는 버전(예: LangChain Python v0.x, v0. long-term)과 백엔드(Linode, OpenAI, Cohere 등)를 알려주시면 정확한 import 경로와 코드 예제를 제공합니다.\\n\\n원하시면 바로 따라 할 수 있는 간단한 Python 빠른 시작 코드와, 자주 쓰는 패턴별 예제(메모리 있는 대화, 벡터 스토어 연결, 간단한 에이전트)를 하나의 연속 예제로 만들어 드리겠습니다. 어떤 분야나 사용 사례부터 시작하고 싶으신가요?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da223905",
   "metadata": {},
   "source": [
    "### stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d57d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! 무슨 도움이 필요해? 원하는 주제나 작업이 있으면 말해줘.\n",
      "\n",
      "예시:\n",
      "- 간단한 대화 연습이나 연습문제\n",
      "- 정보 찾기/정리\n",
      "- 글쓰기 도움이나 첨삭\n",
      "- 번역이나 표현 다듬기\n",
      "- 아이디어 브레인스토밍\n",
      "- 코딩 도움이나 설명\n",
      "\n",
      "무슨 주제로 시작할까?"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(\"안녕\"):\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5000dcb5",
   "metadata": {},
   "source": [
    "### batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afbe3a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 무엇을 도와드릴까요? 질문이 있거나 글쓰기, 번역, 아이디어 뽑기, 코딩 문제 등 무엇이든 말씀해 주세요.\n",
      "랭체인(LangChain)은 LLM(대형언어모델)을 이용한 애플리케이션을 쉽게 만들고 관리하게 해주는 오픈소스 프레임워크예요. 프롬프트를 한 줄로만 쓰는 것을 넘어, 여러 단계의 처리 흐름(chain)을 구성하고 외부 도구(도메인 API, 계산기, 검색 등)와의 연동까지 체계적으로 다룰 수 있도록 도와줍니다.\n",
      "\n",
      "주요 개념\n",
      "- Chain(체인): 여러 단계의 표준화된 흐름으로, 프롬프트를 만들고 LLM 호출, 결과 처리 등을 순차적으로 연결합니다.\n",
      "- PromptTemplate(프롬프트 템플릿): 입력 변수를 채워 넣어 재사용 가능한 프롬프트를 만드는 도구.\n",
      "- LLM/Tools: 언어모델 호출과 외부 도구(검색 API, 계산기, 데이터베이스 쿼리 등)를 함께 사용해 복합 작업을 수행합니다.\n",
      "- Agent(에이전트): 목표를 주면 어떤 도구를 언제 사용할지 판단하고, 필요에 따라 체인을 동적으로 구성하는 반사적 판단 로직을 포함합니다.\n",
      "- Memory(메모리): 대화 맥락이나 중간 결과를 저장해 다음 단계에서 활용합니다.\n",
      "- Vector store/Retriever(벡터 저장소/검색기): 문서나 데이터에 대한 임베딩 기반 검색을 통해 검색 기반의 증강 생성(RAG)을 구현합니다.\n",
      "- Callbacks: 토큰 스트리밍, 로깅, 모니터링 등 실행에 대한 피드백을 처리합니다.\n",
      "\n",
      "왜 유용한가\n",
      "- 복잡한 워크플로우를 코드 한 줄로 구현하지 않고도 쉽게 구성할 수 있습니다.\n",
      "- 프롬프트 재사용성과 구성 요소의 재사용성이 높아 개발 속도가 빨라집니다.\n",
      "- 데이터 소스, 도구, 벡터 저장소 등 다양한 시스템을 통합하기 쉬워져서 Q&A, 문서 요약, 자동화된 리포트 생성 등 여러 용도에 맞춤화가 가능합니다.\n",
      "\n",
      "자주 쓰는 사용 사례\n",
      "- 문서 검색 기반 Q&A: 문서를 벡터 저장소에 저장하고 필요 시 검색된 정보를 바탕으로 답변 생성.\n",
      "- 기억을 가진 챗봇: 대화 맥락을 저장하고 반복 대화에서도 맥락을 활용한 응답 생성.\n",
      "- 자동화된 분석 파이프라인: 외부 API 호출, 데이터 변환, 결과 요약을 체인으로 묶음.\n",
      "- 도구 활용 에이전트: 계산기, 스프레드시트 API, 웹 검색 등의 도구를 상황에 맞게 동적으로 호출.\n",
      "\n",
      "시작하는 방법(간단한 가이드)\n",
      "- 목표에 맞는 체인/에이전트 구성으로 시작해 보세요. 예를 들어 간단한 Q&A 체인이나 문서 요약 체인부터 시작하는 것이 좋습니다.\n",
      "- 기본 구성 예시: 프롬프트 템플릿 만들기 → LLM 호출 → 결과 처리 → 필요 시 메모리에 저장.\n",
      "- 필요에 따라 벡터 저장소를 연결해 검색 기반 증강을 추가할 수 있습니다.\n",
      "\n",
      "참고 자료\n",
      "- LangChain 공식 문서 및 가이드: LangChain 웹사이트와 GitHub 저장소에서 튜토리얼과 예제를 확인할 수 있습니다.\n",
      "- Python/TypeScript 지원: Python과 JavaScript/TypeScript 두 가지 주된 SDK가 제공됩니다.\n",
      "- 일반적인 도구 연동 예: 검색 API, 계산기, 데이터베이스 쿼리, 문서 파싱 등과의 연결 방법이 문서에 정리되어 있습니다.\n",
      "\n",
      "원하시면 구체적인 사용 예나 간단한 코드 예제로 시작해 드리겠습니다. 예를 들어 “문서 집합에서 질문에 답하는 간단한 체인 만들기” 같은 목표를 알려주시면 맞춤 예제와 단계별 설명을 제공할게요.\n"
     ]
    }
   ],
   "source": [
    "input = [\n",
    "    \"안녕\",\n",
    "    \"랭체인이란?\"\n",
    "]\n",
    "\n",
    "responses = model.batch(input)\n",
    "for response in responses:\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03ead15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"상세한 영화 정보.\"\"\"\n",
    "    title: str = Field(description=\"영화의 제목\")       # Field객체 없어도 필수 필드와 타입만으로 답변 생성 가능\n",
    "    year: int = Field(description=\"개봉 연도\")                  # Field는 자세한 설명을 위해 추가하는 사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3880499",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_structure = model.with_structured_output(Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db72d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Movie(title='Avatar 3', year=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_structure.invoke(\"영화 아바타 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b8c36",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b2e4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "system_msg = SystemMessage(\"당신은 유능한 로켓 전문가 입니다.\")\n",
    "human_msg = HumanMessage(\"안녕하세요. 궁금한 것이 있어요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "931a3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [system_msg, human_msg]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc8f434a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='반갑습니다! 로켓 전문가로서 도움드리겠습니다.\\n\\n무슨 부분이 궁금한지 구체적으로 알려주실 수 있을까요? 원하신다면 초보자용 설명부터 수식까지 자세히 풀어드릴 수 있어요. 또는 바로 하나의 주제를 선택해서 알려주셔도 됩니다.\\n\\n다음과 같은 주제에서 시작해볼 수 있어요:\\n- 로켓 엔진의 작동 원리 (추진력의 기본 개념)\\n- 추진력과 질량의 관계: 로켓 방정식(Tsiolkovsky) 간단 설명\\n- 궤도 기초: 궤도 속도, 궤도 삽입, 궤도 전이\\n- 발사 절차와 시스템 구성(상승단계, 페이로드, 제어 시스템 등)\\n- 재진입/재사용성과 관련된 이슈\\n- 안전과 시험 절차에 대한 기본 원리\\n\\n원하시는 방식으로 시작해도 좋습니다. 예를 들어 지금 바로 “로켓 방정식의 간단한 예제”나 “기본 궤도 역학의 개념 설명” 같이 특정 주제로 시작해 드릴 수 있습니다. 질문만 남겨주시면 바로 답변드리겠습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 985, 'prompt_tokens': 31, 'total_tokens': 1016, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-DA7hgg3t4NiacCrnpiDdxV8arLXdE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c6a05-64f2-73d0-8908-b3eec7713575-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 31, 'output_tokens': 985, 'total_tokens': 1016, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18224308",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role': \"system\", \"content\": \"당신은 유능한 AI 어시스턴트입니다.\"},\n",
    "    {'role': \"human\", \"content\": \"안녕하세요 저는 Jay입니다!\"},\n",
    "    {'role': \"ai\", \"content\": \"안녕하세요 Jay! 어떤 도움이 필요하신가요?\"},\n",
    "    {'role': 'human', \"content\": \"제 이름이 뭐라고 했죠?\"}\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fbea4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='당신의 이름은 Jay입니다. 도움이 더 필요하신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 473, 'prompt_tokens': 60, 'total_tokens': 533, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-DA7os0Olrewo9yCbtgZGVWAK3mJgT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c6a0c-33a6-7ab3-9f4a-80dba7e08e55-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 60, 'output_tokens': 473, 'total_tokens': 533, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import List, Dict\n",
    "\n",
    "@tool\n",
    "def search_news(web_url: str) -> List[Dict[str, str]]:      # 특정 사이트(네이버 뉴스)에서 기사 url과 제목을 가져온다.\n",
    "    pass\n",
    "\n",
    "# 제목을 통해 db에 겹치는 뉴스 있는지 확인\n",
    "# 없을 시 아래 도구 실행\n",
    "\n",
    "@tool\n",
    "def read_news(url: str):        # 뉴스 요약 사에 뉴스를 청크단위로 쪼개야 하는지 등의 데이터 입력 형태 고려                 \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cf307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "class NewsAnalysis(BaseModel):\n",
    "    \"\"\"뉴스 내용을 분석한 결과 구조\"\"\"\n",
    "    subject: Literal[\"company\", \"what\", \"why\", \"with_company\"] = Field(\n",
    "        description=\"뉴스의 주제: 어떤 기업이 무엇을, 왜, 어떤 기업과, 의 내용을 요약\" \\\n",
    "        \"예) company: A기업, what: 실적 발표, why: None, with_company: None\" \\\n",
    "        \"예) company: A기업, what: 계약 체결, why: 기업의 시장 확장, with_company: B기업\"\n",
    "    )\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(description=\"감정 상태\")\n",
    "    expectation: str = Field(description=\"기자가 남긴 주가 변동에 대한 의견, 없다면 직접 만들어서 의견 작성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e360d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[search_news, read_news],\n",
    "    response_format=ToolStrategy[NewsAnalysis]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
